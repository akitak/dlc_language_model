{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a361873b-50d5-46f3-a433-5b76a5a86170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51114175-d7d9-4f0d-bcf2-d017dff487ac",
   "metadata": {},
   "source": [
    "**Importing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35a952fb-a5a4-46ad-96d9-044e8c8f95ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "file_name = 'input.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58aee6b8-7923-4882-9ef4-2f02969ad6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: urllib.request documentation suggests possibility of urlretrieve may deprecate in near future\n",
    "if not os.path.exists(file_name):\n",
    "    urlretrieve(url, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7443a5d9-d09c-47d8-b7c0-92eec28ddc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c273a393-6f01-48d2-bf55-dcd7bbf2535d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9325af6-f81d-4ebd-921d-680b906c5568",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85a9112d-44bd-4d12-ac88-50f9c9781abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Hyperparameters\n",
    "block_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcba8f1a-4343-42b8-8b64-c1da2115690e",
   "metadata": {},
   "source": [
    "**Testing `class CharDataset`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "172e8534-c965-41f7-9100-f056099a9499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of characters.\n",
    "\n",
    "    Adapted from \"https://github.com/karpathy/minGPT\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block_size, data): # Going to define block_size in notebook above instantiation of CharDataset object when reading data / training model\n",
    "    # def __init__(self, config, data):\n",
    "\n",
    "        self.data = data # IMPLEMENTED\n",
    "        self.block_size = block_size # IMPLEMENTED\n",
    "\n",
    "        chars = sorted(list(set(self.data))) # get characters from the input data # IMPLEMENTED\n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) } # map characters to integer indices\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) } # similarly, map integer to indices, necessary for decoding and prediction # IMPLEMENTED\n",
    "        self.vocab_size = len(chars) # IMPLEMENTED\n",
    "        self.data_size = len(self.data) # IMPLEMENTED\n",
    "        \n",
    "        \n",
    "        ...\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size # IMPLEMENTED\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_size - self.block_size # IMPLEMENTED # Number of training samples using a sliding window of length block_size #TODO: IMPLEMENT Config\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.data[idx:idx+self.block_size+1]# grab a chunk of (block_size + 1) characters from the data\n",
    "        encoded_tensor = torch.tensor([self.stoi[c] for c in chunk], dtype=torch.long) # encode every character to an integer # IMPLEMENTED\n",
    "        # decode = lambda integers: ''.join([self.itos[integer] for integer in integers]) # decode every character to an integer # IMPLEMENTED\n",
    "        # return the chunk and the shifted version as tensors\n",
    "        x = encoded_tensor[:-1] # IMPLEMENTED\n",
    "        y = encoded_tensor[1:] # IMPLEMENTED\n",
    "        return x, y # IMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5887dc2-04db-483a-a5ca-866072b1516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCONTINUED: Since I'm passing block_size in as a parameter only\n",
    "# config = '' # Should be no issue since nothing references config at the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e56df3b3-450e-43eb-8114-4566ca3ee4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chardataset = CharDataset(block_size=block_size, data=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "991711b9-1942-4e66-9380-a93168a38e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '3': 9,\n",
       " ':': 10,\n",
       " ';': 11,\n",
       " '?': 12,\n",
       " 'A': 13,\n",
       " 'B': 14,\n",
       " 'C': 15,\n",
       " 'D': 16,\n",
       " 'E': 17,\n",
       " 'F': 18,\n",
       " 'G': 19,\n",
       " 'H': 20,\n",
       " 'I': 21,\n",
       " 'J': 22,\n",
       " 'K': 23,\n",
       " 'L': 24,\n",
       " 'M': 25,\n",
       " 'N': 26,\n",
       " 'O': 27,\n",
       " 'P': 28,\n",
       " 'Q': 29,\n",
       " 'R': 30,\n",
       " 'S': 31,\n",
       " 'T': 32,\n",
       " 'U': 33,\n",
       " 'V': 34,\n",
       " 'W': 35,\n",
       " 'X': 36,\n",
       " 'Y': 37,\n",
       " 'Z': 38,\n",
       " 'a': 39,\n",
       " 'b': 40,\n",
       " 'c': 41,\n",
       " 'd': 42,\n",
       " 'e': 43,\n",
       " 'f': 44,\n",
       " 'g': 45,\n",
       " 'h': 46,\n",
       " 'i': 47,\n",
       " 'j': 48,\n",
       " 'k': 49,\n",
       " 'l': 50,\n",
       " 'm': 51,\n",
       " 'n': 52,\n",
       " 'o': 53,\n",
       " 'p': 54,\n",
       " 'q': 55,\n",
       " 'r': 56,\n",
       " 's': 57,\n",
       " 't': 58,\n",
       " 'u': 59,\n",
       " 'v': 60,\n",
       " 'w': 61,\n",
       " 'x': 62,\n",
       " 'y': 63,\n",
       " 'z': 64}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chardataset.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87035077-8042-4ccb-a5fe-54736084d98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\n',\n",
       " 1: ' ',\n",
       " 2: '!',\n",
       " 3: '$',\n",
       " 4: '&',\n",
       " 5: \"'\",\n",
       " 6: ',',\n",
       " 7: '-',\n",
       " 8: '.',\n",
       " 9: '3',\n",
       " 10: ':',\n",
       " 11: ';',\n",
       " 12: '?',\n",
       " 13: 'A',\n",
       " 14: 'B',\n",
       " 15: 'C',\n",
       " 16: 'D',\n",
       " 17: 'E',\n",
       " 18: 'F',\n",
       " 19: 'G',\n",
       " 20: 'H',\n",
       " 21: 'I',\n",
       " 22: 'J',\n",
       " 23: 'K',\n",
       " 24: 'L',\n",
       " 25: 'M',\n",
       " 26: 'N',\n",
       " 27: 'O',\n",
       " 28: 'P',\n",
       " 29: 'Q',\n",
       " 30: 'R',\n",
       " 31: 'S',\n",
       " 32: 'T',\n",
       " 33: 'U',\n",
       " 34: 'V',\n",
       " 35: 'W',\n",
       " 36: 'X',\n",
       " 37: 'Y',\n",
       " 38: 'Z',\n",
       " 39: 'a',\n",
       " 40: 'b',\n",
       " 41: 'c',\n",
       " 42: 'd',\n",
       " 43: 'e',\n",
       " 44: 'f',\n",
       " 45: 'g',\n",
       " 46: 'h',\n",
       " 47: 'i',\n",
       " 48: 'j',\n",
       " 49: 'k',\n",
       " 50: 'l',\n",
       " 51: 'm',\n",
       " 52: 'n',\n",
       " 53: 'o',\n",
       " 54: 'p',\n",
       " 55: 'q',\n",
       " 56: 'r',\n",
       " 57: 's',\n",
       " 58: 't',\n",
       " 59: 'u',\n",
       " 60: 'v',\n",
       " 61: 'w',\n",
       " 62: 'x',\n",
       " 63: 'y',\n",
       " 64: 'z'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chardataset.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a349aab-f56f-478d-b8d5-3377e2345c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chardataset.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eadd8521-0297-4cff-9d2e-9591b0f4a3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115391"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chardataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c32154b-925b-4517-98a9-d0fae85aa94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([56, 57, 58,  1]), tensor([57, 58,  1, 15]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chardataset.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15e97f59-68d7-4ce8-bf27-d88750f3bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = CharDataset(block_size=block_size, data='Akira')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd95a372-efe2-4ff9-8989-4eba222f68ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd8ca322-6320-43b0-82dd-2707d7d2a603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c522cda0-5a9d-4b01-a347-451d9e41db78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 3, 2, 4]), tensor([3, 2, 4, 1]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c642935-f785-42da-8c9d-2f7c4a32fbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 2, 4]), tensor([2, 4, 1]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b87aa09d-5788-4964-8f54-16381db29706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 4]), tensor([4, 1]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0583e40f-04fa-4734-bb89-cceaed680340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4]), tensor([1]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.__getitem__(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bfc68fa-cf43-4478-9ec1-ff50dd0a20a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([], dtype=torch.int64), tensor([], dtype=torch.int64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.__getitem__(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61661ecc-bdfe-48bb-ac72-69df4967daa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
