{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e36457-5220-448d-a15c-9cf22a84308f",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a361873b-50d5-46f3-a433-5b76a5a86170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f149cace-8b33-4f95-96ed-f03cbdd391a5",
   "metadata": {},
   "source": [
    "# Transformer Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6154073-7463-4be9-8128-829ad2b621fd",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "![Fig1](figures/fig1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5bd7730-1c6d-4ae7-91f6-96d02d329744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be markdown ![Fig2](figures/fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51114175-d7d9-4f0d-bcf2-d017dff487ac",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35a952fb-a5a4-46ad-96d9-044e8c8f95ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "file_name = 'input.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58aee6b8-7923-4882-9ef4-2f02969ad6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: urllib.request documentation suggests possibility of urlretrieve may deprecate in near future\n",
    "if not os.path.exists(file_name):\n",
    "    urlretrieve(url, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7443a5d9-d09c-47d8-b7c0-92eec28ddc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c273a393-6f01-48d2-bf55-dcd7bbf2535d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9325af6-f81d-4ebd-921d-680b906c5568",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85a9112d-44bd-4d12-ac88-50f9c9781abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a character-level language model, each character in the input data is mapped to its respective index from a dictionary. \n",
    "# The input to the model is in the form (B, N), where B is the batch size and N is the number of tokens for each sequence. \n",
    "# The model was tested with B=N=128, but feel free to explore different values.\n",
    "\n",
    "# Data Hyperparameters\n",
    "# block_size =  # Consistent with miniproject2_language_model.ipynb instructions\n",
    "# batch_size = \n",
    "\n",
    "# emb_dim = 768\n",
    "# n_heads = 8\n",
    "# n_layers = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1db648-9071-4c62-8a48-a924d20b70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The project was tested with 12 layers, 8 attention heads, and 768 embedding dimensions, on a single GPU.\n",
    "\n",
    "# Model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcba8f1a-4343-42b8-8b64-c1da2115690e",
   "metadata": {},
   "source": [
    "# Implementing `class CharDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "172e8534-c965-41f7-9100-f056099a9499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of characters.\n",
    "\n",
    "    Adapted from \"https://github.com/karpathy/minGPT\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block_size, data): # Going to define block_size in notebook above instantiation of CharDataset object when reading data / training model\n",
    "    # def __init__(self, config, data):\n",
    "\n",
    "        self.data = data # IMPLEMENTED\n",
    "        self.block_size = block_size # IMPLEMENTED\n",
    "\n",
    "        chars = sorted(list(set(self.data))) # get characters from the input data # IMPLEMENTED\n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) } # map characters to integer indices\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) } # similarly, map integer to indices, necessary for decoding and prediction # IMPLEMENTED\n",
    "        self.vocab_size = len(chars) # IMPLEMENTED\n",
    "        self.data_size = len(self.data) # IMPLEMENTED\n",
    "        \n",
    "        \n",
    "        ...\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size # IMPLEMENTED\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_size - self.block_size # IMPLEMENTED # Number of training samples using a sliding window of length block_size #TODO: IMPLEMENT Config\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.data[idx:idx+self.block_size+1]# grab a chunk of (block_size + 1) characters from the data\n",
    "        encoded_tensor = torch.tensor([self.stoi[c] for c in chunk], dtype=torch.long) # encode every character to an integer # IMPLEMENTED\n",
    "        # return the chunk and the shifted version as tensors\n",
    "        x = encoded_tensor[:-1] # IMPLEMENTED\n",
    "        y = encoded_tensor[1:] # IMPLEMENTED\n",
    "        return x, y # IMPLEMENTED\n",
    "\n",
    "def decode(encoded): # decode every integer to a character # IMPLEMENTED\n",
    "    return ''.join([self.itos[integer] for integer in encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5887dc2-04db-483a-a5ca-866072b1516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCONTINUED: Since I'm passing block_size in as a parameter only\n",
    "# config = '' # Should be no issue since nothing references config at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d0b3d1-92cd-4e34-8224-21c7e80fb95c",
   "metadata": {},
   "source": [
    "# Testing `CharDataset` implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e56df3b3-450e-43eb-8114-4566ca3ee4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size_example = 4 # Just for testing purposes\n",
    "chardataset = CharDataset(block_size=block_size_example, data=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec23eef-6b2b-4fd2-935b-969d8ca241f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chardataset.data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f198ff6-8bc1-42a5-8346-d0917d9b69b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chardataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc85747-fdd2-4670-879e-277bd8c91c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chardataset.block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991711b9-1942-4e66-9380-a93168a38e6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chardataset.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87035077-8042-4ccb-a5fe-54736084d98c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chardataset.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7e462a-e5d5-4edd-9619-f90801002adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chardataset.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf1cd7f-dd28-4a40-a8dd-97f0be1f4724",
   "metadata": {},
   "outputs": [],
   "source": [
    "chardataset.data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a349aab-f56f-478d-b8d5-3377e2345c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "chardataset.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd8521-0297-4cff-9d2e-9591b0f4a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chardataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bec958-58c9-425c-8be9-0acf953eed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "chardataset.data_size - chardataset.block_size == chardataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32154b-925b-4517-98a9-d0fae85aa94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chardataset.__getitem__(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34be46ed-f615-4a39-b4a3-3f74999a4686",
   "metadata": {},
   "source": [
    "## Example if I used my name as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e97f59-68d7-4ce8-bf27-d88750f3bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = CharDataset(block_size=4, data='Akira')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabec088-3dd2-4dd9-8259-e79e9019e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd95a372-efe2-4ff9-8989-4eba222f68ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8ca322-6320-43b0-82dd-2707d7d2a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c522cda0-5a9d-4b01-a347-451d9e41db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c642935-f785-42da-8c9d-2f7c4a32fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87aa09d-5788-4964-8f54-16381db29706",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0583e40f-04fa-4734-bb89-cceaed680340",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.__getitem__(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc68fa-cf43-4478-9ec1-ff50dd0a20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.__getitem__(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed871384-8dc5-4928-a185-e95e2394f5b8",
   "metadata": {},
   "source": [
    "## Creation of Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db6df6-41d7-46fb-a50a-64191d725556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "# PyTorch docs for random_split: https://docs.pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6c790-24c8-47d5-85ff-9f8487585cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CharDataset(block_size=128, data=text)\n",
    "\n",
    "train, test = random_split(dataset, [0.9, 0.1])\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_loader  = DataLoader(test, batch_size=128, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c753c9-528c-4aa2-85b0-a89bf3b2dc3b",
   "metadata": {},
   "source": [
    "# Implementing `Model.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd0fd7-1a7d-43a8-a811-5a9717fef798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e334e8a7-285d-4ba4-b29e-b60aa67aebe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64dca79d-b187-4a76-8d92-69a3ad41e3e5",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6561f-7472-4a85-90fd-19bdc3b78da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6085e557-b59a-4843-b026-e985c2bcfad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
